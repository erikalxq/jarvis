<!DOCTYPE html>
<html lang="zh">
<head>
<meta charset="UTF-8" />
<title>Jarvis Core</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<style>
html, body {
    margin: 0;
    padding: 0;
    background: #000;
    width: 100%;
    height: 100%;
    overflow: hidden;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
}

#container {
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    height: 100%;
}

canvas {
    width: 320px;
    height: 120px;
}

#text {
    margin-top: 28px;
    max-width: 80%;
    text-align: center;
    font-size: 15px;
    line-height: 1.6;
    color: #9fdcdc;
    opacity: 1;
    transition: opacity 0.5s ease;
}
</style>
</head>

<body>
<div id="container">
    <canvas id="wave"></canvas>
    <div id="text">点击唤醒，让我听到你的声音</div>
</div>

<div id="controls" style="position:fixed; right:16px; top:16px; color:#9fdcdc;">
    <input id="ttsInput" type="text" placeholder="测试 TTS 文本" style="width:220px;padding:6px;border-radius:4px;border:1px solid #333;background:#000;color:#9fdcdc;" />
    <button id="ttsPlayBtn" style="margin-left:6px;padding:6px 10px;border-radius:4px;border:1px solid #333;background:#073;background-color:#063;color:#fff;">播放 TTS</button>
</div>

<script>
/* =========================
   Canvas & DPI
========================= */
const canvas = document.getElementById('wave');
const ctx = canvas.getContext('2d');

const DPR = window.devicePixelRatio || 1;
const W = 320;
const H = 120;

canvas.width = W * DPR;
canvas.height = H * DPR;
canvas.style.width = W + 'px';
canvas.style.height = H + 'px';
ctx.scale(DPR, DPR);

/* =========================
   状态
========================= */
const STATE = {
    IDLE: 'idle',
    LISTENING: 'listening',
    THINKING: 'thinking',
    SPEAKING: 'speaking'
};
let state = STATE.IDLE;
let prevState = null;
let ttsAudioCtx = null;
let ttsAnalyser = null;
let ttsDataArray = null;

/* =========================
   文案
========================= */
const textEl = document.getElementById('text');

function setText(t) {
    textEl.textContent = t;
    textEl.style.opacity = 1;
}

/* =========================
   音频
========================= */
let audioCtx, analyser, dataArray;
let micStream = null;   // 新增：保存 MediaStream
let lastSoundTime = 0;
let micDataArray = null;

async function initAudio() {
    // 如果已经有 stream 就直接复用
    if (micStream && audioCtx) return;

    micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    audioCtx = new AudioContext();
    const source = audioCtx.createMediaStreamSource(micStream);

    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 512;
    // make mic analyser a bit smoother but responsive
    analyser.smoothingTimeConstant = 0.3;
    analyser.minDecibels = -90;
    micDataArray = new Uint8Array(analyser.fftSize);

    source.connect(analyser);
}

/* =========================
   声音能量
========================= */
let energy = 0;
let energyTarget = 0;

function updateEnergy() {
    // Choose analyser depending on current state (mic when listening, tts when speaking)
    let srcAnalyser = null;
    let srcArray = null;
    if (state === STATE.LISTENING && analyser) {
        srcAnalyser = analyser;
        srcArray = micDataArray;
    } else if (state === STATE.SPEAKING && ttsAnalyser) {
        srcAnalyser = ttsAnalyser;
        srcArray = ttsDataArray;
    } else if (analyser) {
        // fallback to mic analyser in other states if available
        srcAnalyser = analyser;
        srcArray = micDataArray;
    }

    if (!srcAnalyser || !srcArray) return;

    srcAnalyser.getByteTimeDomainData(srcArray);
    let sum = 0;
    for (let i = 0; i < srcArray.length; i++) {
        const v = (srcArray[i] - 128) / 128;
        sum += v * v;
    }

    const rms = Math.sqrt(sum / srcArray.length);

    // Sensitivity multiplier: increase to make small sounds more visible
    energyTarget = Math.min(1, rms * 20);

    // Update lastSoundTime when loud enough (for listening timeout)
    if (state === STATE.LISTENING && energyTarget > 0.2) {
        lastSoundTime = performance.now();
    }
}

/* =========================
   波形基础
========================= */
let time = 0;
const baseAmp = 10;

const seed = Math.random() * 1000;
function softNoise(x, k = 1) {
    return (
        Math.sin(x * 0.8 * k + seed) * 0.6 +
        Math.sin(x * 1.6 * k + seed * 2) * 0.3
    );
}

function sampleWave(amp, freqMul, phase) {
    const points = [];
    const centerY = H / 2;

    for (let x = 0; x <= W; x += 1) {
        const nx = x * 0.02 * freqMul;
        const v =
            Math.sin(nx + time + phase) * 0.6 +
            softNoise(nx + time, freqMul) * 0.4;

        const fade = Math.exp(-Math.pow((x - W / 2) / 150, 2));
        points.push({
            x,
            y: centerY + v * amp * fade
        });
    }
    return points;
}

/* =========================
   绘制曲线
========================= */
function drawLine(points, alpha, width, color = '0,255,255') {
    ctx.beginPath();
    ctx.moveTo(points[0].x, points[0].y);

    for (let i = 1; i < points.length - 2; i++) {
        const xc = (points[i].x + points[i + 1].x) / 2;
        const yc = (points[i].y + points[i + 1].y) / 2;
        ctx.quadraticCurveTo(points[i].x, points[i].y, xc, yc);
    }

    ctx.strokeStyle = `rgba(${color},${alpha})`;
    ctx.lineWidth = width;
    ctx.lineCap = 'round';
    ctx.lineJoin = 'round';
    ctx.stroke();
}

/* =========================
   流式文字
========================= */
let buffer = [];
let fullText = "";

async function streamChat(text) {
    buffer = [];
    fullText = "";
    setText("");
    const res = await fetch("/api/chat/stream", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text })
    });

    const reader = res.body.getReader();
    const decoder = new TextDecoder();
    let resultText = '';
    while (true) {
        const { value, done } = await reader.read();
        if (done) break;
        const chunk = decoder.decode(value);
        chunk.split("\n").forEach(line => {
            if (line.startsWith("data: ")) {
                const piece = line.replace("data: ", "");
                buffer.push(piece);
                resultText += piece;
            }
        });
    }

    return resultText;
}


/* =========================
   录音 & 发送到 STT
========================= */
let mediaRecorder = null;
let audioChunks = [];
async function sendToSTT(blob) {
    // 切换到 THINKING 状态并更新文案
    prevState = state;
    state = STATE.THINKING;
    setText('思考中，请稍后');

    const formData = new FormData();
    formData.append('audio', blob);

    try {
        const res = await fetch('/api/transcribe', {
            method: 'POST',
            body: formData
        });

        if (!res.ok) {
            const txt = await res.text();
            console.error('transcribe failed:', res.status, txt);
            setText('识别失败，请稍后重试');
            return;
        }

        const data = await res.json();
        onSttFinish(data);
        // setText(`你刚才说的是：\n“${data.text}”`);
    } catch (err) {
        console.error('sendToSTT error', err);
        setText('识别失败，请稍后重试');
    } finally {
        // 恢复到空闲状态（也可以恢复到 prevState，如果需要）
        state = STATE.IDLE;
    }
}

// Play streamed PCM16 audio from /api/tts-stream?text=...
async function playTTSStream(text) {
    if (!text) return;

    // close previous ttsAudioCtx if any
    try {
        if (ttsAudioCtx && ttsAudioCtx.state !== 'closed') {
            ttsAudioCtx.close();
        }
    } catch (e) {}

    ttsAudioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
    ttsAnalyser = ttsAudioCtx.createAnalyser();
    ttsAnalyser.fftSize = 512;
    // make TTS analyser very responsive
    ttsAnalyser.smoothingTimeConstant = 0.05;
    ttsAnalyser.minDecibels = -100;
    ttsDataArray = new Uint8Array(ttsAnalyser.fftSize);

    const gain = ttsAudioCtx.createGain();
    gain.gain.value = 1.0;
    ttsAnalyser.connect(gain);
    gain.connect(ttsAudioCtx.destination);

    // set state to SPEAKING
    prevState = state;
    state = STATE.SPEAKING;
    setText('播放语音中...');

    const url = '/api/tts-stream?text=' + encodeURIComponent(text);
    const res = await fetch(url);
    if (!res.ok || !res.body) {
        console.error('TTS stream fetch failed', res.status);
        state = prevState || STATE.IDLE;
        return;
    }

    const contentType = (res.headers.get('content-type') || '').toLowerCase();

    // If the server returned a WAV container (fallback when ffmpeg isn't available),
    // read the full blob and decode it via decodeAudioData for reliable playback.
    if (contentType.includes('audio/wav') || contentType.includes('audio/x-wav')) {
        try {
            const blob = await res.blob();
            const arrayBuffer = await blob.arrayBuffer();
            const audioBuffer = await ttsAudioCtx.decodeAudioData(arrayBuffer);

            const src = ttsAudioCtx.createBufferSource();
            src.buffer = audioBuffer;
            src.connect(ttsAnalyser);
            src.start(ttsAudioCtx.currentTime + 0.05);

            // when playback ends, restore state
            src.onended = () => {
                try { ttsAudioCtx.close(); } catch (e) {}
                ttsAudioCtx = null;
                ttsAnalyser = null;
                ttsDataArray = null;
                state = prevState || STATE.IDLE;
                setText('点击唤醒，让我听到你的声音');
            };
        } catch (e) {
            console.error('Error decoding WAV blob from TTS stream', e);
            try { ttsAudioCtx.close(); } catch (er) {}
            ttsAudioCtx = null;
            ttsAnalyser = null;
            ttsDataArray = null;
            state = prevState || STATE.IDLE;
            setText('播放失败');
        }
        return;
    }

    // Otherwise we expect raw PCM (s16le) streamed in chunks. Make sure to honor
    // the Uint8Array.byteOffset when creating a DataView — using value.buffer alone
    // can result in misaligned reads and noisy audio.
    const reader = res.body.getReader();
    const SAMPLE_RATE = 16000;

    // We'll schedule buffers sequentially
    let playTime = ttsAudioCtx.currentTime + 0.05;
    try {
        let leftover = null;
        let lastSource = null;
        while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            if (!value || value.byteLength === 0) continue;

            let data = value;

            // If we have a leftover byte from the previous chunk, prepend it
            if (leftover) {
                const merged = new Uint8Array(leftover.byteLength + value.byteLength);
                merged.set(leftover, 0);
                merged.set(value, leftover.byteLength);
                data = merged;
                leftover = null;
            }

            // If we have an odd number of bytes, save the last byte for the next round
            if (data.byteLength % 2 !== 0) {
                leftover = data.slice(data.byteLength - 1);
                data = data.slice(0, data.byteLength - 1);
            }

            if (data.byteLength === 0) continue;

            const view = new DataView(data.buffer, data.byteOffset, data.byteLength);
            const sampleCount = data.byteLength / 2;
            const float32 = new Float32Array(sampleCount);

            for (let i = 0; i < sampleCount; i++) {
                float32[i] = view.getInt16(i * 2, true) / 32768;
            }

            const buffer = ttsAudioCtx.createBuffer(1, float32.length, SAMPLE_RATE);
            buffer.copyToChannel(float32, 0);

            const src = ttsAudioCtx.createBufferSource();
            src.buffer = buffer;
            src.connect(ttsAnalyser);
            src.start(playTime);
            playTime += buffer.duration;
            lastSource = src;
        }

    } catch (e) {
        console.error('Error reading TTS stream', e);
    } finally {
        if (lastSource) {
            lastSource.onended = () => {
                try { ttsAudioCtx.close(); } catch (e) {}
                ttsAudioCtx = null;
                ttsAnalyser = null;
                ttsDataArray = null;
                state = prevState || STATE.IDLE;
                setText('点击唤醒，让我听到你的声音');
            };
        } else {
            // fallback
            state = prevState || STATE.IDLE;
        }
    }
}

/* =========================
   录音结束
========================= */
async function onSttFinish(sttText) {
    const reply = await streamChat(sttText);
    // after streaming response text to UI, play TTS for the reply
    // reply may be empty if streaming failed
    if (reply && reply.length > 0) {
        playTTSStream(reply);
    }
}

function stopRecordingAndCleanup() {
    // 停止 mediaRecorder 并在 onstop 时提交数据
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.onstop = async () => {
            const blob = new Blob(audioChunks, { type: 'audio/webm' });
            await sendToSTT(blob);
        };
        try {
            mediaRecorder.stop();
        } catch (e) {
            console.warn('mediaRecorder stop error', e);
        }
    }

    // 停止所有麦克风轨道
    if (micStream) {
        micStream.getTracks().forEach(track => {
            try { track.stop(); } catch (e) {}
        });
        micStream = null;
    }

    // 关闭 audioCtx，释放资源
    if (audioCtx) {
        try { audioCtx.close(); } catch (e) {}
        audioCtx = null;
        analyser = null;
        dataArray = null;
    }

    mediaRecorder = null;
    audioChunks = [];
}


/* =========================
   主循环
========================= */
function render() {
    ctx.clearRect(0, 0, W, H);

    updateEnergy();

    // 能量平滑 + 衰减
    // 更快地跟随目标值，并且衰减更慢以保留更大的可视幅度
    energy += (energyTarget - energy) * 0.12;
    energy *= 0.985;

    if (buffer.length > 0) {
        fullText += buffer.shift();
        setText(fullText);
        energyTarget = Math.min(1, energyTarget + 0.2);
    }

    // Idle 几乎不动；在 SPEAKING 时也使用能量以显示播放时的波形
    const activeEnergy = (state === STATE.LISTENING || state === STATE.SPEAKING) ? energy : 0.02;
    // 增大能量对幅度的影响，使波动更明显
    const amp = baseAmp + activeEnergy * 40;

    // 三条不同“生命层”
    // 三条不同“生命层”
    const main = sampleWave(amp, 1.0, 0);
    const thin1 = sampleWave(amp * 0.6, 1.4, 1.7);
    const thin2 = sampleWave(amp * 0.45, 0.8, -2.3);

    // 根据状态改变颜色/透明度/线宽，THINKING 时使用柔和黄色并降低动画频率
    if (state === STATE.THINKING) {
        drawLine(thin1, 0.18, 1, '255,200,100');
        drawLine(thin2, 0.18, 1, '255,200,100');
        drawLine(main, 0.7, 2.2, '255,220,140');
    } else {
        drawLine(thin1, 0.25, 1);
        drawLine(thin2, 0.25, 1);
        drawLine(main, 0.9, 1.8);
    }

    // Listening 超时检测（3 秒无声）
    if (
        state === STATE.LISTENING &&
        performance.now() - lastSoundTime > 3000
    ) {
        state = STATE.IDLE;
        setText('点击唤醒，让我听到你的声音');

        // 停止录音并发送已录制数据
        stopRecordingAndCleanup();
    }

    time += 0.012 + activeEnergy * 0.02;
    requestAnimationFrame(render);
}

/* =========================
   点击交互
========================= */
document.body.addEventListener('click', async () => {
    if (state === STATE.LISTENING || state === STATE.THINKING || state === STATE.SPEAKING) 
        return;
    
    // 初始化并复用同一流
    if (!micStream || !audioCtx) {
        await initAudio();
    }

    // 如果还没有在录音，创建并开始
    if (!mediaRecorder || mediaRecorder.state === 'inactive') {
        mediaRecorder = new MediaRecorder(micStream);
        audioChunks = [];

        mediaRecorder.ondataavailable = e => {
            if (e.data.size > 0) audioChunks.push(e.data);
        };

        mediaRecorder.start();

        state = STATE.LISTENING;
        lastSoundTime = performance.now();
        setText('我在，请说');
    }  
});

// tts play button
const ttsPlayBtn = document.getElementById('ttsPlayBtn');
const ttsInput = document.getElementById('ttsInput');
ttsPlayBtn.addEventListener('click', async () => {
    const txt = (ttsInput && ttsInput.value) ? ttsInput.value.trim() : '';
    if (!txt) return;
    // if currently recording or thinking, ignore
    if (state === STATE.LISTENING || state === STATE.THINKING) return;
    // play the tts stream and let waveform update
    await playTTSStream(txt);
});

/* =========================
   启动
========================= */
render();
</script>
</body>
</html>
