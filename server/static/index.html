<!DOCTYPE html>
<html lang="zh">
<head>
<meta charset="UTF-8" />
<title>Jarvis Core</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<style>
html, body {
    margin: 0;
    padding: 0;
    background: #000;
    width: 100%;
    height: 100%;
    overflow: hidden;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
}

#container {
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    height: 100%;
}

canvas {
    width: 320px;
    height: 120px;
}

#text {
    margin-top: 28px;
    max-width: 80%;
    text-align: center;
    font-size: 15px;
    line-height: 1.6;
    color: #9fdcdc;
    opacity: 1;
    transition: opacity 0.5s ease;
}
</style>
</head>

<body>
<div id="container">
    <canvas id="wave"></canvas>
    <div id="text">点击唤醒，让我听到你的声音</div>
</div>

<script>
/* =========================
   Canvas & DPI
========================= */
const canvas = document.getElementById('wave');
const ctx = canvas.getContext('2d');

const DPR = window.devicePixelRatio || 1;
const W = 320;
const H = 120;

canvas.width = W * DPR;
canvas.height = H * DPR;
canvas.style.width = W + 'px';
canvas.style.height = H + 'px';
ctx.scale(DPR, DPR);

/* =========================
   状态
========================= */
const STATE = {
    IDLE: 'idle',
    LISTENING: 'listening'
};
let state = STATE.IDLE;

/* =========================
   文案
========================= */
const textEl = document.getElementById('text');

function setText(t) {
    textEl.textContent = t;
    textEl.style.opacity = 1;
}

/* =========================
   音频
========================= */
let audioCtx, analyser, dataArray;
let micStream = null;   // 新增：保存 MediaStream
let lastSoundTime = 0;

async function initAudio() {
    // 如果已经有 stream 就直接复用
    if (micStream && audioCtx) return;

    micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    audioCtx = new AudioContext();
    const source = audioCtx.createMediaStreamSource(micStream);

    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 512;
    dataArray = new Uint8Array(analyser.fftSize);

    source.connect(analyser);
}

/* =========================
   声音能量
========================= */
let energy = 0;
let energyTarget = 0;

function updateEnergy() {
    if (!analyser) return;

    analyser.getByteTimeDomainData(dataArray);
    let sum = 0;

    for (let i = 0; i < dataArray.length; i++) {
        const v = (dataArray[i] - 128) / 128;
        sum += v * v;
    }

    const rms = Math.sqrt(sum / dataArray.length);

    // Sensitivity multiplier: increase to make small sounds more visible
    energyTarget = Math.min(1, rms * 6);

    // Lower the threshold so quieter sounds update the lastSoundTime
    if (energyTarget > 0.02) {
        //lastSoundTime = performance.now();
    }
}

/* =========================
   波形基础
========================= */
let time = 0;
const baseAmp = 10;

const seed = Math.random() * 1000;
function softNoise(x, k = 1) {
    return (
        Math.sin(x * 0.8 * k + seed) * 0.6 +
        Math.sin(x * 1.6 * k + seed * 2) * 0.3
    );
}

function sampleWave(amp, freqMul, phase) {
    const points = [];
    const centerY = H / 2;

    for (let x = 0; x <= W; x += 1) {
        const nx = x * 0.02 * freqMul;
        const v =
            Math.sin(nx + time + phase) * 0.6 +
            softNoise(nx + time, freqMul) * 0.4;

        const fade = Math.exp(-Math.pow((x - W / 2) / 150, 2));
        points.push({
            x,
            y: centerY + v * amp * fade
        });
    }
    return points;
}

/* =========================
   绘制曲线
========================= */
function drawLine(points, alpha, width) {
    ctx.beginPath();
    ctx.moveTo(points[0].x, points[0].y);

    for (let i = 1; i < points.length - 2; i++) {
        const xc = (points[i].x + points[i + 1].x) / 2;
        const yc = (points[i].y + points[i + 1].y) / 2;
        ctx.quadraticCurveTo(points[i].x, points[i].y, xc, yc);
    }

    ctx.strokeStyle = `rgba(0,255,255,${alpha})`;
    ctx.lineWidth = width;
    ctx.lineCap = 'round';
    ctx.lineJoin = 'round';
    ctx.stroke();
}


let mediaRecorder = null;
let audioChunks = [];
async function sendToSTT(blob) {
    alert('将发送录音到服务器(/api/transcribe)进行语音识别，确认后继续');

    const formData = new FormData();
    formData.append('audio', blob);

    const res = await fetch('/api/transcribe', {
        method: 'POST',
        body: formData
    });

    const data = await res.json();
    setText(`你刚才说的是：\n“${data.text}”`);
}

function stopRecordingAndCleanup() {
    // 停止 mediaRecorder 并在 onstop 时提交数据
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.onstop = async () => {
            const blob = new Blob(audioChunks, { type: 'audio/webm' });
            await sendToSTT(blob);
        };
        try {
            mediaRecorder.stop();
        } catch (e) {
            console.warn('mediaRecorder stop error', e);
        }
    }

    // 停止所有麦克风轨道
    if (micStream) {
        micStream.getTracks().forEach(track => {
            try { track.stop(); } catch (e) {}
        });
        micStream = null;
    }

    // 关闭 audioCtx，释放资源
    if (audioCtx) {
        try { audioCtx.close(); } catch (e) {}
        audioCtx = null;
        analyser = null;
        dataArray = null;
    }

    mediaRecorder = null;
    audioChunks = [];
}

/* =========================
   主循环
========================= */
function render() {
    ctx.clearRect(0, 0, W, H);

    updateEnergy();

    // 能量平滑 + 衰减
    // 更快地跟随目标值，并且衰减更慢以保留更大的可视幅度
    energy += (energyTarget - energy) * 0.12;
    energy *= 0.985;

    // Idle 几乎不动
    const activeEnergy = state === STATE.LISTENING ? energy : 0.02;
    // 增大能量对幅度的影响，使波动更明显
    const amp = baseAmp + activeEnergy * 40;

    // 三条不同“生命层”
    const main = sampleWave(amp, 1.0, 0);
    const thin1 = sampleWave(amp * 0.6, 1.4, 1.7);
    const thin2 = sampleWave(amp * 0.45, 0.8, -2.3);

    drawLine(thin1, 0.25, 1);
    drawLine(thin2, 0.25, 1);
    drawLine(main, 0.9, 1.8);

    // Listening 超时检测（3 秒无声）
    if (
        state === STATE.LISTENING &&
        performance.now() - lastSoundTime > 3000
    ) {
        state = STATE.IDLE;
        setText('点击唤醒，让我听到你的声音');

        // 停止录音并发送已录制数据
        stopRecordingAndCleanup();
    }

    time += 0.012 + activeEnergy * 0.02;
    requestAnimationFrame(render);
}

/* =========================
   点击交互
========================= */
document.body.addEventListener('click', async () => {
    // 初始化并复用同一流
    if (!micStream || !audioCtx) {
        await initAudio();
    }

    // 如果还没有在录音，创建并开始
    if (!mediaRecorder || mediaRecorder.state === 'inactive') {
        mediaRecorder = new MediaRecorder(micStream);
        audioChunks = [];

        mediaRecorder.ondataavailable = e => {
            alert('录音数据可用，大小：' + e.data.size + ' 字节');
            if (e.data.size > 0) audioChunks.push(e.data);
        };

        mediaRecorder.start();
        alert('mediaRecorder 启动，开始录音。');
    }

    state = STATE.LISTENING;
    lastSoundTime = performance.now();
    setText('我在，请说');
});

/* =========================
   启动
========================= */
render();
</script>
</body>
</html>
